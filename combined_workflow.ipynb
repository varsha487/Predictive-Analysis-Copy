{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combined Workflow\n",
    "Notes: \n",
    "* Continued issues accessing articles behind a paywall or external source (e.g., https://finance.yahoo.com/news/top-midday-stories-pepsico-buy-160405890.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import csv\n",
    "from time import sleep\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from seleniumbase import Driver\n",
    "from pymongo import MongoClient\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "import torch\n",
    "from bs4 import BeautifulSoup\n",
    "import google.generativeai as genai\n",
    "import json\n",
    "from openai import OpenAI\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################\n",
    "# Get website html data \n",
    "##################################\n",
    "def get_basesoup(driver, url, wait=False, until_class='ClassOfMyElement'):\n",
    "    driver.get(url)\n",
    "\n",
    "    # Wait for page and element to completely load\n",
    "    if wait:\n",
    "        delay = 3 # seconds\n",
    "        try:\n",
    "            WebDriverWait(driver, delay).until(EC.presence_of_element_located((By.CLASS_NAME, until_class)))\n",
    "        except TimeoutException:\n",
    "            print(\"Loading took too much time!\")\n",
    "    \n",
    "    basesoup=BeautifulSoup(driver.page_source,\"html.parser\")\n",
    "    return basesoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################\n",
    "#Return a list of strings for a given url, \n",
    "#where each string is a sentence in the linked article.\n",
    "##################################\n",
    "def get_news_info(url):\n",
    "    '''\n",
    "    Return a list of strings for a given url, \n",
    "    where each string is a sentence in the linked article.\n",
    "    '''\n",
    "    soup = get_basesoup(driver, url)\n",
    "\n",
    "    try:\n",
    "        article = soup.find(\"div\", class_=\"article-wrap no-bb\")\n",
    "        \n",
    "        if not article:\n",
    "            print(f\"No articles found on page {url}\")\n",
    "            return []\n",
    "\n",
    "        # cover_wrap = article.find(\"div\", class_=\"cover-wrap yf-1p8y0lh\")\n",
    "        # title = cover_wrap.find(\"h1\", class_=\"cover-title yf-1p8y0lh\")\n",
    "             \n",
    "        body_wrap = article.find(\"div\", class_=\"body-wrap yf-i23rhs\")\n",
    "        body = body_wrap.find(\"div\", class_=\"body yf-5ef8bf\")\n",
    "        text = body.find_all(\"p\", class_=\"yf-1pe5jgt\")\n",
    "        # for paragraph in text:\n",
    "        #     print(paragraph.text.strip())\n",
    "        \n",
    "        return [paragraph.text.strip() for paragraph in text]\n",
    "            \n",
    "        \n",
    "    except:\n",
    "        print(f\"Error accessing articles on page {url}\")\n",
    "        return []\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################\n",
    "#gets URLS from yahoo finance API\n",
    "########################################\n",
    "def get_urls_yfinance(ticker):\n",
    "    news = yf.Ticker(ticker).news\n",
    "    urls = {dictionary['link'] for dictionary in news}\n",
    "    return urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################\n",
    "# Scrape all related articles\n",
    "########################################\n",
    "def get_list_all_articles_text_data(urls):\n",
    "    article_texts = []\n",
    "    \n",
    "    for url in urls:\n",
    "        article_texts.append(get_news_info(url)) #webscraping step\n",
    "\n",
    "    return article_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################\n",
    "#Combine list of sentences\n",
    "##################################\n",
    "def combine_sentences(text_data):\n",
    "    output_text = \"\"\n",
    "    for sentence in text_data:\n",
    "        output_text += \" \" + sentence\n",
    "    return output_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################\n",
    "#get finbert sentiment scores for one text\n",
    "#################################\n",
    "def use_finbert(text_data):\n",
    "    text = combine_sentences(text_data)\n",
    "    tokenizer = BertTokenizer.from_pretrained('yiyanghkust/finbert-tone')\n",
    "    model = BertForSequenceClassification.from_pretrained('yiyanghkust/finbert-tone')\n",
    "    inputs = tokenizer(text, return_tensors='pt', max_length=512, truncation=True, padding=True)\n",
    "    # Get model predictions\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    # Extract the logits (raw output predictions)\n",
    "    logits = outputs.logits\n",
    "    \n",
    "    # Convert logits to probabilities using softmax\n",
    "    probs = torch.nn.functional.softmax(logits, dim=-1)\n",
    "    \n",
    "    # Extract probabilities and predicted sentiment class\n",
    "    predicted_class = torch.argmax(probs).item()  # 0: negative, 1: neutral, 2: positive\n",
    "    confidence = torch.max(probs).item()\n",
    "\n",
    "    # Sentiment mapping\n",
    "    sentiment_labels = ['Negative', 'Neutral', 'Positive']\n",
    "    \n",
    "    # Get the predicted sentiment label\n",
    "    predicted_sentiment = sentiment_labels[predicted_class]\n",
    "    \n",
    "    # Set a confidence threshold (e.g., 70%)\n",
    "    confidence_threshold = 0.7\n",
    "    \n",
    "    # Output result with a check on confidence\n",
    "    # if confidence >= confidence_threshold:\n",
    "    #     print(f\"Sentiment: {predicted_sentiment} (Confidence: {confidence:.2f})\")\n",
    "    # else:\n",
    "    #     print(\"Sentiment prediction not reliable enough based on confidence threshold.\")\n",
    "    return [predicted_sentiment, confidence]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################\n",
    "#get aggregate sentiment scores from one day from finbert\n",
    "##############################################\n",
    "def get_sentiment_scores_finbert(article_texts):\n",
    "    cnt_neu = 0\n",
    "    cnt_pos = 0\n",
    "    cnt_neg = 0\n",
    "    total_confidence = 0\n",
    "    for text in article_texts:\n",
    "        sentiment, confidence = use_finbert(text)\n",
    "        if sentiment == \"Neutral\":\n",
    "            cnt_neu += 1\n",
    "        elif sentiment == \"Positive\":\n",
    "            cnt_pos += 1\n",
    "        elif sentiment == \"Negative\":\n",
    "            cnt_neg += 1\n",
    "        total_confidence += confidence\n",
    "    return [cnt_neu, cnt_pos, cnt_neg, total_confidence/len(article_texts)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################\n",
    "#get gemini sentiment scores for one text\n",
    "#################################\n",
    "def get_gemini_sentiment_score_one_article(api_key_gemini, text):\n",
    "    genai.configure(api_key=api_key_gemini)\n",
    "    model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "    response = model.generate_content(\"Please conduct sentiment analysis on the following articles of interest. Here is the text: \"+text+\n",
    "                                  '''Output text should be in JSON format with no extra information or text. Do NOT include extra formatting.\n",
    "                                  Your response should start with { and end with }. Do not include `.\n",
    "                                  Include categories neutral-sentiment,''' +\n",
    "                                  \"positive-sentiment, negative-sentiment, summary and stock-tickers. The sentiment categories should include \"+\n",
    "                                  \"an integer from 0 to 9, where 0 means that the text doesn't fit that category and 9 means it fits well.\" +\n",
    "                                  \"The summary should be a once-sentence summary about the text. Stock-tickers should be the tickers of stocks related\" +\n",
    "                                  \"to the articles.\" +\n",
    "                                  '''If no article is given, output an empty \n",
    "                                  json \"{}\" only. Here is an example of required formatting: ''' +\n",
    "\n",
    "                                  ''' {\"neutral-sentiment\": #,\n",
    "                                    \"npositive-sentiment\": #,\n",
    "                                    \"negative-sentiment\": #,\n",
    "                                    \"related-stocks\": [\"ABC\", \"DEF\", \"GHI\"] +\n",
    "                                    \"nsummary : \"Include a 2-sentence summary of the article text here.\" +\n",
    "                                    }''')\n",
    "    response_string = response.text\n",
    "    if response_string == \"{}\":\n",
    "        return None\n",
    "    try:\n",
    "        response_json = json.loads(response_string)\n",
    "    except json.JSONDecodeError:\n",
    "        return {}\n",
    "    return response_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################\n",
    "#get OpenAI sentiment scores for one text\n",
    "#make sure to change the api_key string to\n",
    "#appropriate key\n",
    "#################################\n",
    "def get_openai_sentiment_score_one_article(text):\n",
    "    client = OpenAI(\n",
    "        api_key= \"\"\n",
    "        #api_key= \"\"\n",
    "    )\n",
    "    # Construct the prompt dynamically\n",
    "    prompt = (\"Please conduct sentiment analysis on the following articles of interest. Here is the text: \" + text +\n",
    "              '''Output text should be in JSON format with no extra information or text. Do NOT include extra formatting.\n",
    "              Your response should start with { and end with }. Do not include `.\n",
    "              Include categories neutral-sentiment, positive-sentiment, negative-sentiment, summary and stock-tickers. The sentiment categories should include \n",
    "              an integer from 0 to 9, where 0 means that the text doesn't fit that category and 9 means it fits well. \n",
    "              The summary should be a one-sentence summary about the text. Stock-tickers should be the tickers of stocks related \n",
    "              to the articles.\n",
    "              If no article is given, output an empty \n",
    "              json \"{}\" only. Do not include any newline characters in your responseHere is an example of required formatting: \n",
    "    \n",
    "              {\"neutral-sentiment\": #,\n",
    "               \"positive-sentiment\": #,\n",
    "               \"negative-sentiment\": #,\n",
    "               \"related-stocks\": [\"ABC\", \"DEF\", \"GHI\"]\n",
    "              }'''\n",
    "    )\n",
    "    \n",
    "    # Make the API call to OpenAI\n",
    "    chat_completion = client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\":prompt,\n",
    "            }\n",
    "        ],\n",
    "        model=\"gpt-4o\",\n",
    "        #api_key = \n",
    "    )\n",
    "    \n",
    "    # Extract the assistant's response from the API response\n",
    "    response_string = chat_completion.choices[0].message.content\n",
    "    if response_string == \"{}\":\n",
    "        return {}\n",
    "    try:\n",
    "        response_json = json.loads(response_string)\n",
    "    except json.JSONDecodeError:\n",
    "        return {}\n",
    "        print(\"here\")\n",
    "    return response_json\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################\n",
    "#get aggregate sentiment scores from one day from OpenAI\n",
    "##############################################\n",
    "def get_all_openai_scores(article_texts):\n",
    "    avg_neu = 0\n",
    "    avg_pos = 0\n",
    "    avg_neg = 0\n",
    "    num_articles = len(article_texts)\n",
    "    for article in article_texts:\n",
    "        text_data = combine_sentences(article)\n",
    "        sentiment_scores = get_openai_sentiment_score_one_article(text_data)\n",
    "        if not sentiment_scores:\n",
    "            continue\n",
    "        else:\n",
    "            avg_neu += sentiment_scores[\"neutral-sentiment\"]\n",
    "            avg_pos += sentiment_scores[\"positive-sentiment\"]\n",
    "            avg_neg += sentiment_scores[\"negative-sentiment\"]\n",
    "    try:\n",
    "        scores =  [avg_neu/num_articles, avg_pos/num_articles, avg_neg/num_articles]\n",
    "    except ZeroDivisionError:\n",
    "        scores =  [0,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################\n",
    "#get aggregate sentiment scores from one day from gemini\n",
    "##############################################\n",
    "def get_all_gemini_sentiment_scores(article_texts):\n",
    "    avg_neu = 0\n",
    "    avg_pos = 0\n",
    "    avg_neg = 0\n",
    "    api_key_gemini= \"\"\n",
    "    num_articles = len(article_texts)\n",
    "    for article in article_texts:\n",
    "        text_data = combine_sentences(article)\n",
    "        sentiment_scores = get_gemini_sentiment_score_one_article(api_key_gemini, text_data)\n",
    "        if not sentiment_scores:\n",
    "            continue\n",
    "        else:\n",
    "            avg_neu += sentiment_scores[\"neutral-sentiment\"]\n",
    "            avg_pos += sentiment_scores[\"positive-sentiment\"]\n",
    "            avg_neg += sentiment_scores[\"negative-sentiment\"]\n",
    "    try:\n",
    "        scores =  [avg_neu/num_articles, avg_pos/num_articles, avg_neg/num_articles]\n",
    "    except ZeroDivisionError:\n",
    "        scores =  [0,0,0]\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################\n",
    "#make pandas dataframe for one stock one day\n",
    "##############################################\n",
    "def make_dataframe(ticker):\n",
    "    data = yf.download(ticker, start = datetime.now(), end = datetime.now())\n",
    "    df = pd.DataFrame(data)\n",
    "    urls = get_urls_yfinance(ticker)\n",
    "    article_texts = get_list_all_articles_text_data(urls)\n",
    "    \n",
    "    sentiment_labels_finbert = [\"neutral-count-finbert\", \"positive-count-finbert\",\"negative-count-finbert\",\"average-confidence-finbert\"]\n",
    "    sentiment_scores_finbert = get_sentiment_scores_finbert(article_texts)\n",
    "    for i in range(len(sentiment_labels_finbert)):\n",
    "      df[sentiment_labels_finbert[i]] = sentiment_scores_finbert[i]\n",
    "\n",
    "    sentiment_labels_gemini = [\"average-neutral-score-gemini\", \"average-positive-score-gemini\",\"average-negative-score-gemini\"]\n",
    "    sentiment_scores_gemini = get_all_openai_scores(article_texts)\n",
    "    for i in range(len(sentiment_labels_gemini)):\n",
    "        try:\n",
    "            df[sentiment_labels_gemini[i]] = sentiment_scores_gemini[i]\n",
    "        except TypeError:\n",
    "            df[sentiment_labels_gemini[i]] = 0\n",
    "        \n",
    "    df[\"prediction-label\"] = ''\n",
    "    df['ticker'] = ticker\n",
    "    df['number-employees'] = get_num_employees(ticker)\n",
    "    df['date_object'] = ''\n",
    "    df['sector'] = sectors[ticker]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################\n",
    "#Get number of employees using yahoo finance API\n",
    "#If getting number of employees is unsuccesful,\n",
    "#add an entry in the num_employees_dict manually.\n",
    "##############################################\n",
    "def get_num_employees(ticker):\n",
    "    num_employees_dict = {'TSM': 76478,\n",
    "                     'SBUX': 381000,\n",
    "                     'V': 105400,\n",
    "                     }\n",
    "    stock = yf.Ticker(ticker)\n",
    "    try:\n",
    "        return stock.info['fullTimeEmployees']\n",
    "    except KeyError:\n",
    "        try:\n",
    "            return num_employees_dict[ticker]\n",
    "        except KeyError:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################\n",
    "#Update MongoDB database by adding the dataframe\n",
    "#passed as an argument\n",
    "##############################################\n",
    "def update_db(df):\n",
    "    connection_string = \"\"\n",
    "\n",
    "    # Step 1: Connect to MongoDB Atlas\n",
    "    client = MongoClient(connection_string)\n",
    "    \n",
    "    # Step 2: Select the database and collection\n",
    "    db = client[\"predictive-analysis-dataset\"]  # Replace with your database name\n",
    "    collection = db[\"stocks\"]  # Replace with your collection name\n",
    "    \n",
    "    # Step 4: Convert DataFrame to List of Dictionaries\n",
    "    data = df.to_dict(orient=\"records\")  # Converts rows into a list of dictionaries\n",
    "    \n",
    "    # Step 5: Insert data into MongoDB Atlas collection\n",
    "    try:\n",
    "        collection.insert_many(data)\n",
    "    except TypeError:\n",
    "        print(\"Not uploaded to MongoDB\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################\n",
    "#Updates the prediction by using the previous day's\n",
    "#close and the next day's open. This updates the prediction\n",
    "#of one stock.\n",
    "##############################################\n",
    "def update_prediction_one_stock(stock_ticker, filename):\n",
    "    df = pd.read_csv('stock_data.csv')\n",
    "    stock_df = df[df['ticker'] == stock_ticker]\n",
    "    stock_df = stock_df.reset_index(drop=True)\n",
    "    dates_list = list(stock_df['Date'].unique())\n",
    "    for i in range(1,len(dates_list)):\n",
    "        prev_close = stock_df.loc[i-1, 'Close']\n",
    "        next_open = stock_df.loc[i, 'Open']\n",
    "        didIncrease = False\n",
    "        if prev_close < next_open:\n",
    "            didIncrease = True\n",
    "            stock_df.loc[i, 'prediction-label'] = 1\n",
    "        elif next_open <= prev_close:\n",
    "            didIncrease = False\n",
    "            stock_df.loc[i, 'prediction-label'] = 0\n",
    "    stock_df_index = 0\n",
    "    for index, row in df.iterrows():\n",
    "        if row['ticker'] == stock_ticker:\n",
    "            df.loc[index, 'prediction-label'] = stock_df.loc[stock_df_index, 'prediction-label']\n",
    "            stock_df_index += 1\n",
    "    df.to_csv(filename, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################\n",
    "#Updates all predictions in the dataframe by comparing the \n",
    "#current day's open and close.\n",
    "##############################################\n",
    "def update_all_predictions(filename):\n",
    "    df = pd.read_csv(filename)\n",
    "    for index, row in df.iterrows():\n",
    "        if row['Open'] > row['Close']:\n",
    "            df.loc[index, 'prediction-label'] = 0\n",
    "        else:\n",
    "            df.loc[index, 'prediction-label'] = 1\n",
    "    df.to_csv(filename, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################\n",
    "#Updates all the entries in the number of employees\n",
    "#column\n",
    "##############################################\n",
    "def update_num_employees(filename):\n",
    "    df = pd.read_csv(filename)\n",
    "    for index, row in df.iterrows():\n",
    "        if pd.isna(df.loc[index, 'number-employees']):\n",
    "            df.loc[index, 'number-employees'] = get_num_employees(row['ticker'])\n",
    "    df.to_csv(filename, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################\n",
    "#Updates all the entries in the sector\n",
    "#column\n",
    "##############################################\n",
    "def update_all_sectors(filename):\n",
    "    df = pd.read_csv(filename)\n",
    "    for index, row in df.iterrows():\n",
    "        df.loc[index, 'sector'] = sectors[row['ticker']]\n",
    "    df.to_csv(filename, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################\n",
    "# Stock ticker list that can be updated with any tickers\n",
    "# when more financial and sentiment data needs to be collected.\n",
    "##############################################\n",
    "stock_ticker_list = [ 'LCID' ,'PFE', 'VZ', 'NVDA', 'JNJ', 'T', 'RTX', 'MDT', 'GOOGL', 'BSX', 'META',\n",
    "                   'TSLA', 'AAPL', 'ABNB', 'AMZN', 'MSFT', 'V', \n",
    "                     'WMT', 'PYPL', 'MA', 'DIS', 'NFLX', 'AMD', 'INTU', \n",
    "                     'GS', 'MS', 'KO', 'XOM', 'IBM', 'CVX', 'UNH', 'PEP', 'HD',\n",
    "                     'NKE', 'MCD', 'CSCO', 'BABA', 'BA', 'UNP', 'CAT', 'GE', 'ORCL', 'AMGN',\n",
    "                     'LMT', 'COP', 'TXN', 'ZM', 'SQ', 'SO', 'AXP', 'DHR', 'COST', 'DE', \n",
    "                     'LOW', 'KHC', 'BIDU', 'TMO', 'UAL', \n",
    "                    'WFC', 'CL', 'UPS', 'PM', 'BHP', 'TSM', 'SAP', 'C', 'QCOM', 'INTC', \n",
    "                     'SLB', 'VLO', \n",
    "                    'CSX', 'AMT', 'DUK', 'NSC', 'STZ', 'LLY', 'KMI', 'CHTR', 'PG', \n",
    "                     'LUV', 'F',\n",
    "                    'PGR', 'TGT', 'MCO', 'PRU', 'PLD', 'AIG', 'SPG', 'DOW', 'SBUX', 'MSCI', 'TRV', \n",
    "                    'ZTS', 'MMM', 'EXC', 'FIS', 'ISRG']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################\n",
    "# Each stock ticker above is associated with a \n",
    "# sector in this dictionary. When a stock ticker\n",
    "# is added/deleted, entries in the sector dict\n",
    "# must be added/deleted too.\n",
    "\n",
    "# Sector Categories:\n",
    "# Technology: Companies involved in electronics, software, and hardware (e.g., Apple, Microsoft, NVIDIA, Intel).\n",
    "# Finance: Banks, insurance, investment firms (e.g., JPMorgan, Goldman Sachs, Visa, PayPal).\n",
    "# Healthcare: Pharmaceutical companies, medical devices, healthcare providers (e.g., Pfizer, Johnson & Johnson, Medtronic, Amgen).\n",
    "# Consumer Goods: Companies that produce goods for personal consumption (e.g., Coca-Cola, PepsiCo, McDonald's, Procter & Gamble).\n",
    "# Energy: Oil, gas, renewable energy, utilities (e.g., ExxonMobil, Chevron, Duke Energy).\n",
    "# Industrials: Companies in manufacturing, construction, defense, aerospace (e.g., Boeing, Honeywell, Lockheed Martin).\n",
    "# Telecommunications: Companies that provide communication services (e.g., Verizon, AT&T, Comcast).\n",
    "# Entertainment: Companies in media and entertainment (e.g., Netflix, Disney).\n",
    "# Automotive: Companies related to cars, trucks, and electric vehicles (e.g., Tesla, Ford, Lucid Motors).\n",
    "# Aerospace: Companies in aircraft production and space exploration (e.g., Boeing, Lockheed Martin).\n",
    "##############################################\n",
    "sectors = {\n",
    "    'LCID': 'Automotive',\n",
    "    'PFE': 'Healthcare',\n",
    "    'VZ': 'Telecommunications',\n",
    "    'NVDA': 'Technology',\n",
    "    'JNJ': 'Healthcare',\n",
    "    'T': 'Telecommunications',\n",
    "    'RTX': 'Industrials',\n",
    "    'MDT': 'Healthcare',\n",
    "    'GOOGL': 'Technology',\n",
    "    'BSX': 'Healthcare',\n",
    "    'META': 'Technology',\n",
    "    'TSLA': 'Automotive',\n",
    "    'AAPL': 'Technology',\n",
    "    'ABNB': 'Consumer Goods',\n",
    "    'AMZN': 'Consumer Goods',\n",
    "    'MSFT': 'Technology',\n",
    "    'V': 'Finance',\n",
    "    'WMT': 'Consumer Goods',\n",
    "    'PYPL': 'Finance',\n",
    "    'MA': 'Finance',\n",
    "    'DIS': 'Entertainment',\n",
    "    'NFLX': 'Entertainment',\n",
    "    'AMD': 'Technology',\n",
    "    'INTU': 'Technology',\n",
    "    'GS': 'Finance',\n",
    "    'MS': 'Finance',\n",
    "    'KO': 'Consumer Goods',\n",
    "    'XOM': 'Energy',\n",
    "    'IBM': 'Technology',\n",
    "    'CVX': 'Energy',\n",
    "    'UNH': 'Healthcare',\n",
    "    'PEP': 'Consumer Goods',\n",
    "    'HD': 'Consumer Goods',\n",
    "    'NKE': 'Consumer Goods',\n",
    "    'MCD': 'Consumer Goods',\n",
    "    'CSCO': 'Technology',\n",
    "    'BABA': 'Technology',\n",
    "    'BA': 'Aerospace',\n",
    "    'UNP': 'Industrials',\n",
    "    'CAT': 'Industrials',\n",
    "    'GE': 'Industrials',\n",
    "    'ORCL': 'Technology',\n",
    "    'AMGN': 'Healthcare',\n",
    "    'LMT': 'Aerospace',\n",
    "    'COP': 'Energy',\n",
    "    'TXN': 'Technology',\n",
    "    'ZM': 'Technology',\n",
    "    'SQ': 'Technology',\n",
    "    'SO': 'Energy',\n",
    "    'AXP': 'Finance',\n",
    "    'DHR': 'Healthcare',\n",
    "    'COST': 'Consumer Goods',\n",
    "    'DE': 'Industrials',\n",
    "    'LOW': 'Consumer Goods',\n",
    "    'KHC': 'Consumer Goods',\n",
    "    'BIDU': 'Technology',\n",
    "    'TMO': 'Healthcare',\n",
    "    'UAL': 'Aerospace',\n",
    "    'WFC': 'Finance',\n",
    "    'CL': 'Consumer Goods',\n",
    "    'UPS': 'Industrials',\n",
    "    'PM': 'Consumer Goods',\n",
    "    'BHP': 'Energy',\n",
    "    'TSM': 'Technology',\n",
    "    'SAP': 'Technology',\n",
    "    'C': 'Finance',\n",
    "    'QCOM': 'Technology',\n",
    "    'INTC': 'Technology',\n",
    "    'SLB': 'Energy',\n",
    "    'VLO': 'Energy',\n",
    "    'CSX': 'Industrials',\n",
    "    'AMT': 'Telecommunications',\n",
    "    'DUK': 'Energy',\n",
    "    'NSC': 'Industrials',\n",
    "    'STZ': 'Consumer Goods',\n",
    "    'LLY': 'Healthcare',\n",
    "    'KMI': 'Energy',\n",
    "    'SPY': 'Finance',\n",
    "    'CHTR': 'Telecommunications',\n",
    "    'PG': 'Consumer Goods',\n",
    "    'LUV': 'Airlines',\n",
    "    'F': 'Automotive',\n",
    "    'PGR': 'Finance',\n",
    "    'TGT': 'Consumer Goods',\n",
    "    'MCO': 'Finance',\n",
    "    'PRU': 'Finance',\n",
    "    'PLD': 'Real Estate',\n",
    "    'AIG': 'Finance',\n",
    "    'SPG': 'Real Estate',\n",
    "    'DOW': 'Chemicals',\n",
    "    'SBUX': 'Consumer Goods',\n",
    "    'MSCI': 'Finance',\n",
    "    'TRV': 'Finance',\n",
    "    'ZTS': 'Healthcare',\n",
    "    'MMM': 'Industrials',\n",
    "    'EXC': 'Energy',\n",
    "    'FIS': 'Finance',\n",
    "    'ISRG': 'Healthcare'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[77], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#make_dataframe('TSLA') #only necessary if stock_data file has not been created\u001b[39;00m\n\u001b[0;32m      2\u001b[0m options \u001b[38;5;241m=\u001b[39m webdriver\u001b[38;5;241m.\u001b[39mChromeOptions()\n\u001b[1;32m----> 3\u001b[0m driver \u001b[38;5;241m=\u001b[39m Driver(uc\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, incognito\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m stock \u001b[38;5;129;01min\u001b[39;00m stock_ticker_list:\n\u001b[0;32m      5\u001b[0m     curr_df \u001b[38;5;241m=\u001b[39m make_dataframe(stock)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\seleniumbase\\plugins\\driver_manager.py:782\u001b[0m, in \u001b[0;36mDriver\u001b[1;34m(browser, headless, headless1, headless2, headed, locale_code, protocol, servername, port, proxy, proxy_bypass_list, proxy_pac_url, multi_proxy, agent, cap_file, cap_string, recorder_ext, disable_cookies, disable_js, disable_csp, enable_ws, disable_ws, enable_sync, use_auto_ext, undetectable, uc_cdp_events, uc_subprocess, log_cdp_events, no_sandbox, disable_gpu, incognito, guest_mode, dark_mode, devtools, remote_debug, enable_3d_apis, swiftshader, ad_block_on, host_resolver_rules, block_images, do_not_track, chromium_arg, firefox_arg, firefox_pref, user_data_dir, extension_zip, extension_dir, disable_features, binary_location, driver_version, page_load_strategy, use_wire, external_pdf, window_position, window_size, is_mobile, mobile, d_width, d_height, d_p_r, uc, undetected, uc_cdp, uc_sub, log_cdp, ad_block, server, guest, wire, pls)\u001b[0m\n\u001b[0;32m    779\u001b[0m \u001b[38;5;66;03m# Launch a web browser\u001b[39;00m\n\u001b[0;32m    780\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mseleniumbase\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m browser_launcher\n\u001b[1;32m--> 782\u001b[0m driver \u001b[38;5;241m=\u001b[39m browser_launcher\u001b[38;5;241m.\u001b[39mget_driver(\n\u001b[0;32m    783\u001b[0m     browser_name\u001b[38;5;241m=\u001b[39mbrowser_name,\n\u001b[0;32m    784\u001b[0m     headless\u001b[38;5;241m=\u001b[39mheadless,\n\u001b[0;32m    785\u001b[0m     locale_code\u001b[38;5;241m=\u001b[39mlocale_code,\n\u001b[0;32m    786\u001b[0m     use_grid\u001b[38;5;241m=\u001b[39muse_grid,\n\u001b[0;32m    787\u001b[0m     protocol\u001b[38;5;241m=\u001b[39mprotocol,\n\u001b[0;32m    788\u001b[0m     servername\u001b[38;5;241m=\u001b[39mservername,\n\u001b[0;32m    789\u001b[0m     port\u001b[38;5;241m=\u001b[39mport,\n\u001b[0;32m    790\u001b[0m     proxy_string\u001b[38;5;241m=\u001b[39mproxy_string,\n\u001b[0;32m    791\u001b[0m     proxy_bypass_list\u001b[38;5;241m=\u001b[39mproxy_bypass_list,\n\u001b[0;32m    792\u001b[0m     proxy_pac_url\u001b[38;5;241m=\u001b[39mproxy_pac_url,\n\u001b[0;32m    793\u001b[0m     multi_proxy\u001b[38;5;241m=\u001b[39mmulti_proxy,\n\u001b[0;32m    794\u001b[0m     user_agent\u001b[38;5;241m=\u001b[39muser_agent,\n\u001b[0;32m    795\u001b[0m     cap_file\u001b[38;5;241m=\u001b[39mcap_file,\n\u001b[0;32m    796\u001b[0m     cap_string\u001b[38;5;241m=\u001b[39mcap_string,\n\u001b[0;32m    797\u001b[0m     recorder_ext\u001b[38;5;241m=\u001b[39mrecorder_ext,\n\u001b[0;32m    798\u001b[0m     disable_cookies\u001b[38;5;241m=\u001b[39mdisable_cookies,\n\u001b[0;32m    799\u001b[0m     disable_js\u001b[38;5;241m=\u001b[39mdisable_js,\n\u001b[0;32m    800\u001b[0m     disable_csp\u001b[38;5;241m=\u001b[39mdisable_csp,\n\u001b[0;32m    801\u001b[0m     enable_ws\u001b[38;5;241m=\u001b[39menable_ws,\n\u001b[0;32m    802\u001b[0m     enable_sync\u001b[38;5;241m=\u001b[39menable_sync,\n\u001b[0;32m    803\u001b[0m     use_auto_ext\u001b[38;5;241m=\u001b[39muse_auto_ext,\n\u001b[0;32m    804\u001b[0m     undetectable\u001b[38;5;241m=\u001b[39mundetectable,\n\u001b[0;32m    805\u001b[0m     uc_cdp_events\u001b[38;5;241m=\u001b[39muc_cdp_events,\n\u001b[0;32m    806\u001b[0m     uc_subprocess\u001b[38;5;241m=\u001b[39muc_subprocess,\n\u001b[0;32m    807\u001b[0m     log_cdp_events\u001b[38;5;241m=\u001b[39mlog_cdp_events,\n\u001b[0;32m    808\u001b[0m     no_sandbox\u001b[38;5;241m=\u001b[39mno_sandbox,\n\u001b[0;32m    809\u001b[0m     disable_gpu\u001b[38;5;241m=\u001b[39mdisable_gpu,\n\u001b[0;32m    810\u001b[0m     headless1\u001b[38;5;241m=\u001b[39mheadless1,\n\u001b[0;32m    811\u001b[0m     headless2\u001b[38;5;241m=\u001b[39mheadless2,\n\u001b[0;32m    812\u001b[0m     incognito\u001b[38;5;241m=\u001b[39mincognito,\n\u001b[0;32m    813\u001b[0m     guest_mode\u001b[38;5;241m=\u001b[39mguest_mode,\n\u001b[0;32m    814\u001b[0m     dark_mode\u001b[38;5;241m=\u001b[39mdark_mode,\n\u001b[0;32m    815\u001b[0m     devtools\u001b[38;5;241m=\u001b[39mdevtools,\n\u001b[0;32m    816\u001b[0m     remote_debug\u001b[38;5;241m=\u001b[39mremote_debug,\n\u001b[0;32m    817\u001b[0m     enable_3d_apis\u001b[38;5;241m=\u001b[39menable_3d_apis,\n\u001b[0;32m    818\u001b[0m     swiftshader\u001b[38;5;241m=\u001b[39mswiftshader,\n\u001b[0;32m    819\u001b[0m     ad_block_on\u001b[38;5;241m=\u001b[39mad_block_on,\n\u001b[0;32m    820\u001b[0m     host_resolver_rules\u001b[38;5;241m=\u001b[39mhost_resolver_rules,\n\u001b[0;32m    821\u001b[0m     block_images\u001b[38;5;241m=\u001b[39mblock_images,\n\u001b[0;32m    822\u001b[0m     do_not_track\u001b[38;5;241m=\u001b[39mdo_not_track,\n\u001b[0;32m    823\u001b[0m     chromium_arg\u001b[38;5;241m=\u001b[39mchromium_arg,\n\u001b[0;32m    824\u001b[0m     firefox_arg\u001b[38;5;241m=\u001b[39mfirefox_arg,\n\u001b[0;32m    825\u001b[0m     firefox_pref\u001b[38;5;241m=\u001b[39mfirefox_pref,\n\u001b[0;32m    826\u001b[0m     user_data_dir\u001b[38;5;241m=\u001b[39muser_data_dir,\n\u001b[0;32m    827\u001b[0m     extension_zip\u001b[38;5;241m=\u001b[39mextension_zip,\n\u001b[0;32m    828\u001b[0m     extension_dir\u001b[38;5;241m=\u001b[39mextension_dir,\n\u001b[0;32m    829\u001b[0m     disable_features\u001b[38;5;241m=\u001b[39mdisable_features,\n\u001b[0;32m    830\u001b[0m     binary_location\u001b[38;5;241m=\u001b[39mbinary_location,\n\u001b[0;32m    831\u001b[0m     driver_version\u001b[38;5;241m=\u001b[39mdriver_version,\n\u001b[0;32m    832\u001b[0m     page_load_strategy\u001b[38;5;241m=\u001b[39mpage_load_strategy,\n\u001b[0;32m    833\u001b[0m     use_wire\u001b[38;5;241m=\u001b[39muse_wire,\n\u001b[0;32m    834\u001b[0m     external_pdf\u001b[38;5;241m=\u001b[39mexternal_pdf,\n\u001b[0;32m    835\u001b[0m     test_id\u001b[38;5;241m=\u001b[39mtest_id,\n\u001b[0;32m    836\u001b[0m     mobile_emulator\u001b[38;5;241m=\u001b[39mis_mobile,\n\u001b[0;32m    837\u001b[0m     device_width\u001b[38;5;241m=\u001b[39md_width,\n\u001b[0;32m    838\u001b[0m     device_height\u001b[38;5;241m=\u001b[39md_height,\n\u001b[0;32m    839\u001b[0m     device_pixel_ratio\u001b[38;5;241m=\u001b[39md_p_r,\n\u001b[0;32m    840\u001b[0m     browser\u001b[38;5;241m=\u001b[39mbrowser_name,\n\u001b[0;32m    841\u001b[0m )\n\u001b[0;32m    842\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m driver\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\seleniumbase\\core\\browser_launcher.py:2464\u001b[0m, in \u001b[0;36mget_driver\u001b[1;34m(browser_name, headless, locale_code, use_grid, protocol, servername, port, proxy_string, proxy_bypass_list, proxy_pac_url, multi_proxy, user_agent, cap_file, cap_string, recorder_ext, disable_cookies, disable_js, disable_csp, enable_ws, enable_sync, use_auto_ext, undetectable, uc_cdp_events, uc_subprocess, log_cdp_events, no_sandbox, disable_gpu, headless1, headless2, incognito, guest_mode, dark_mode, devtools, remote_debug, enable_3d_apis, swiftshader, ad_block_on, host_resolver_rules, block_images, do_not_track, chromium_arg, firefox_arg, firefox_pref, user_data_dir, extension_zip, extension_dir, disable_features, binary_location, driver_version, page_load_strategy, use_wire, external_pdf, test_id, mobile_emulator, device_width, device_height, device_pixel_ratio, browser)\u001b[0m\n\u001b[0;32m   2402\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m get_remote_driver(\n\u001b[0;32m   2403\u001b[0m         browser_name,\n\u001b[0;32m   2404\u001b[0m         headless,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2461\u001b[0m         device_pixel_ratio,\n\u001b[0;32m   2462\u001b[0m     )\n\u001b[0;32m   2463\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2464\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m get_local_driver(\n\u001b[0;32m   2465\u001b[0m         browser_name,\n\u001b[0;32m   2466\u001b[0m         headless,\n\u001b[0;32m   2467\u001b[0m         locale_code,\n\u001b[0;32m   2468\u001b[0m         servername,\n\u001b[0;32m   2469\u001b[0m         proxy_string,\n\u001b[0;32m   2470\u001b[0m         proxy_auth,\n\u001b[0;32m   2471\u001b[0m         proxy_user,\n\u001b[0;32m   2472\u001b[0m         proxy_pass,\n\u001b[0;32m   2473\u001b[0m         proxy_bypass_list,\n\u001b[0;32m   2474\u001b[0m         proxy_pac_url,\n\u001b[0;32m   2475\u001b[0m         multi_proxy,\n\u001b[0;32m   2476\u001b[0m         user_agent,\n\u001b[0;32m   2477\u001b[0m         recorder_ext,\n\u001b[0;32m   2478\u001b[0m         disable_cookies,\n\u001b[0;32m   2479\u001b[0m         disable_js,\n\u001b[0;32m   2480\u001b[0m         disable_csp,\n\u001b[0;32m   2481\u001b[0m         enable_ws,\n\u001b[0;32m   2482\u001b[0m         enable_sync,\n\u001b[0;32m   2483\u001b[0m         use_auto_ext,\n\u001b[0;32m   2484\u001b[0m         undetectable,\n\u001b[0;32m   2485\u001b[0m         uc_cdp_events,\n\u001b[0;32m   2486\u001b[0m         uc_subprocess,\n\u001b[0;32m   2487\u001b[0m         log_cdp_events,\n\u001b[0;32m   2488\u001b[0m         no_sandbox,\n\u001b[0;32m   2489\u001b[0m         disable_gpu,\n\u001b[0;32m   2490\u001b[0m         headless1,\n\u001b[0;32m   2491\u001b[0m         headless2,\n\u001b[0;32m   2492\u001b[0m         incognito,\n\u001b[0;32m   2493\u001b[0m         guest_mode,\n\u001b[0;32m   2494\u001b[0m         dark_mode,\n\u001b[0;32m   2495\u001b[0m         devtools,\n\u001b[0;32m   2496\u001b[0m         remote_debug,\n\u001b[0;32m   2497\u001b[0m         enable_3d_apis,\n\u001b[0;32m   2498\u001b[0m         swiftshader,\n\u001b[0;32m   2499\u001b[0m         ad_block_on,\n\u001b[0;32m   2500\u001b[0m         host_resolver_rules,\n\u001b[0;32m   2501\u001b[0m         block_images,\n\u001b[0;32m   2502\u001b[0m         do_not_track,\n\u001b[0;32m   2503\u001b[0m         chromium_arg,\n\u001b[0;32m   2504\u001b[0m         firefox_arg,\n\u001b[0;32m   2505\u001b[0m         firefox_pref,\n\u001b[0;32m   2506\u001b[0m         user_data_dir,\n\u001b[0;32m   2507\u001b[0m         extension_zip,\n\u001b[0;32m   2508\u001b[0m         extension_dir,\n\u001b[0;32m   2509\u001b[0m         disable_features,\n\u001b[0;32m   2510\u001b[0m         binary_location,\n\u001b[0;32m   2511\u001b[0m         driver_version,\n\u001b[0;32m   2512\u001b[0m         page_load_strategy,\n\u001b[0;32m   2513\u001b[0m         use_wire,\n\u001b[0;32m   2514\u001b[0m         external_pdf,\n\u001b[0;32m   2515\u001b[0m         mobile_emulator,\n\u001b[0;32m   2516\u001b[0m         device_width,\n\u001b[0;32m   2517\u001b[0m         device_height,\n\u001b[0;32m   2518\u001b[0m         device_pixel_ratio,\n\u001b[0;32m   2519\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\seleniumbase\\core\\browser_launcher.py:3890\u001b[0m, in \u001b[0;36mget_local_driver\u001b[1;34m(browser_name, headless, locale_code, servername, proxy_string, proxy_auth, proxy_user, proxy_pass, proxy_bypass_list, proxy_pac_url, multi_proxy, user_agent, recorder_ext, disable_cookies, disable_js, disable_csp, enable_ws, enable_sync, use_auto_ext, undetectable, uc_cdp_events, uc_subprocess, log_cdp_events, no_sandbox, disable_gpu, headless1, headless2, incognito, guest_mode, dark_mode, devtools, remote_debug, enable_3d_apis, swiftshader, ad_block_on, host_resolver_rules, block_images, do_not_track, chromium_arg, firefox_arg, firefox_pref, user_data_dir, extension_zip, extension_dir, disable_features, binary_location, driver_version, page_load_strategy, use_wire, external_pdf, mobile_emulator, device_width, device_height, device_pixel_ratio)\u001b[0m\n\u001b[0;32m   3887\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m major_chrome_version:\n\u001b[0;32m   3888\u001b[0m     br_app \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgoogle-chrome\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3889\u001b[0m     full_ch_version \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m-> 3890\u001b[0m         detect_b_ver\u001b[38;5;241m.\u001b[39mget_browser_version_from_os(br_app)\n\u001b[0;32m   3891\u001b[0m     )\n\u001b[0;32m   3892\u001b[0m     saved_mcv \u001b[38;5;241m=\u001b[39m full_ch_version\n\u001b[0;32m   3893\u001b[0m     major_chrome_version \u001b[38;5;241m=\u001b[39m full_ch_version\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\seleniumbase\\core\\detect_b_ver.py:352\u001b[0m, in \u001b[0;36mget_browser_version_from_os\u001b[1;34m(browser_type)\u001b[0m\n\u001b[0;32m    350\u001b[0m pattern \u001b[38;5;241m=\u001b[39m PATTERN[browser_type]\n\u001b[0;32m    351\u001b[0m quad_pattern \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md+\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md+\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md+\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md+\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 352\u001b[0m quad_version \u001b[38;5;241m=\u001b[39m read_version_from_cmd(cmd_mapping, quad_pattern)\n\u001b[0;32m    353\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m quad_version \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mstr\u001b[39m(quad_version)) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m9\u001b[39m:  \u001b[38;5;66;03m# Eg. 115.0.0.0\u001b[39;00m\n\u001b[0;32m    354\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m quad_version\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\seleniumbase\\core\\detect_b_ver.py:390\u001b[0m, in \u001b[0;36mread_version_from_cmd\u001b[1;34m(cmd, pattern)\u001b[0m\n\u001b[0;32m    382\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_version_from_cmd\u001b[39m(cmd, pattern):\n\u001b[0;32m    383\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m subprocess\u001b[38;5;241m.\u001b[39mPopen(\n\u001b[0;32m    384\u001b[0m             cmd,\n\u001b[0;32m    385\u001b[0m             stdout\u001b[38;5;241m=\u001b[39msubprocess\u001b[38;5;241m.\u001b[39mPIPE,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    388\u001b[0m             shell\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    389\u001b[0m     ) \u001b[38;5;28;01mas\u001b[39;00m stream:\n\u001b[1;32m--> 390\u001b[0m         stdout \u001b[38;5;241m=\u001b[39m stream\u001b[38;5;241m.\u001b[39mcommunicate()[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdecode()\n\u001b[0;32m    391\u001b[0m         version \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msearch(pattern, stdout)\n\u001b[0;32m    392\u001b[0m         version \u001b[38;5;241m=\u001b[39m version\u001b[38;5;241m.\u001b[39mgroup(\u001b[38;5;241m0\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m version \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\subprocess.py:1196\u001b[0m, in \u001b[0;36mPopen.communicate\u001b[1;34m(self, input, timeout)\u001b[0m\n\u001b[0;32m   1194\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stdin_write(\u001b[38;5;28minput\u001b[39m)\n\u001b[0;32m   1195\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdout:\n\u001b[1;32m-> 1196\u001b[0m     stdout \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdout\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m   1197\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdout\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m   1198\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "##############################################\n",
    "#uncomment the line below if stock_data.csv file hasn't been created\n",
    "#make_dataframe('TSLA') #only necessary if stock_data file has not been created\n",
    "#This makes the dataframe and adds it to the csv file.\n",
    "#THIS HAS TO BE RUN EVERY WEEKDAY TO COLLECT DATA EVERY DAY.\n",
    "##############################################\n",
    "options = webdriver.ChromeOptions()\n",
    "driver = Driver(uc=True, incognito=True)\n",
    "for stock in stock_ticker_list:\n",
    "    curr_df = make_dataframe(stock)\n",
    "    curr_df.to_csv('stock_data.csv', mode = 'a', header = False)\n",
    "    update_db(curr_df)\n",
    "driver.quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
